{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Integración con Google Cloud Functions\n",
        "\n",
        "    Cree una función en Google Cloud Functions:\n",
        "        Ingrese a la consola de Google Cloud.\n",
        "        Vaya a la sección \"Cloud Functions\".\n",
        "        Haga clic en \"Crear función\".\n",
        "\n",
        "    Configure la función:\n",
        "        Asigne un nombre a la función.\n",
        "        Seleccione un disparador HTTP o un evento de Cloud Storage (por ejemplo, creación de objeto en Google Cloud Storage).\n",
        "        Establezca el tiempo de ejecución y otros parámetros.\n",
        "\n",
        "    Suba el script:\n",
        "        En la sección \"Código fuente\", elija \"Editor en línea\" o suba un archivo comprimido con el script.\n",
        "        Pegue el script en el archivo main.py.\n",
        "        Cree un archivo requirements.txt y agregue las dependencias:\n",
        "\n"
      ],
      "metadata": {
        "id": "e9nhfQDwENuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.cloud import storage\n",
        "\n",
        "def clean_and_process_files(bucket_name, source_folder, destination_folder):\n",
        "    # Inicialización del cliente de Google Cloud Storage\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "\n",
        "    # Función para leer y procesar un archivo CSV\n",
        "    def process_file(file_path):\n",
        "        # Carga de datos\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Limpieza de datos eliminando filas con valores nulos\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        # Estandarización de los nombres de las columnas\n",
        "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "        # Devolución del DataFrame procesado\n",
        "        return df\n",
        "\n",
        "    # Función para el procesamiento específico de order_items\n",
        "    def process_order_items(df):\n",
        "        # Conversión de fechas\n",
        "        df['shipping_limit_date'] = pd.to_datetime(df['shipping_limit_date'])\n",
        "        # Creación de nuevas columnas de fecha y hora\n",
        "        df['shipping_date'] = df['shipping_limit_date'].dt.date\n",
        "        df['shipping_time'] = df['shipping_limit_date'].dt.time\n",
        "        return df\n",
        "\n",
        "    # Función para el procesamiento específico de reviews\n",
        "    def process_reviews(df):\n",
        "        # Eliminación de filas con valor 's' en la columna score\n",
        "        df = df[df['score'] != 's']\n",
        "        # Conversión de la columna score a tipo entero\n",
        "        df['score'] = df['score'].astype(int)\n",
        "        return df\n",
        "\n",
        "    # Función para el procesamiento específico de orders\n",
        "    def process_orders(df):\n",
        "        # Rellenar valores nulos en las columnas específicas con una fecha por defecto\n",
        "        df['approved_at'].fillna('1970-01-01 00:00:00', inplace=True)\n",
        "        df['delivered_courier_date'].fillna('1970-01-01 00:00:00', inplace=True)\n",
        "        df['delivered_customer_date'].fillna('1970-01-01 00:00:00', inplace=True)\n",
        "        return df\n",
        "\n",
        "    # Lista de archivos para procesar\n",
        "    files = [\n",
        "        'order_items.csv', 'products.csv', 'reviews.csv', 'sellers.csv',\n",
        "        'customers.csv', 'geolocalizaciones.csv', 'orders.csv', 'order_payments.csv'\n",
        "    ]\n",
        "\n",
        "    # Procesamiento de cada archivo\n",
        "    for file_name in files:\n",
        "        # Descarga del archivo desde Google Cloud Storage\n",
        "        blob = bucket.blob(os.path.join(source_folder, file_name))\n",
        "        blob.download_to_filename(f'/tmp/{file_name}')\n",
        "\n",
        "        # Lectura y procesamiento del archivo\n",
        "        df = process_file(f'/tmp/{file_name}')\n",
        "\n",
        "        # Procesamiento específico para ciertos archivos\n",
        "        if file_name == 'order_items.csv':\n",
        "            df = process_order_items(df)\n",
        "        elif file_name == 'reviews.csv':\n",
        "            df = process_reviews(df)\n",
        "        elif file_name == 'orders.csv':\n",
        "            df = process_orders(df)\n",
        "\n",
        "        # Guardado del archivo procesado de vuelta en Google Cloud Storage\n",
        "        df.to_csv(f'/tmp/processed_{file_name}', index=False)\n",
        "        processed_blob = bucket.blob(os.path.join(destination_folder, f'processed_{file_name}'))\n",
        "        processed_blob.upload_from_filename(f'/tmp/processed_{file_name}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "em9yZS1HKFyp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}